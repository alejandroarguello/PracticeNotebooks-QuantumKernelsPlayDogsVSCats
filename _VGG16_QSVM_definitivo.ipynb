{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDbdfa/GR67P9fr/qgbC5c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["pip install pennylane"],"metadata":{"id":"ljfICxmaG14x"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sdXpE3HvTdx"},"outputs":[],"source":["import zipfile\n","from google.colab import drive\n","drive.mount('/content/drive') #lo concecto con mi drive\n","\n","import cv2\n","import os\n","import numpy as np\n","import torch\n","import torchvision\n","from torchvision import models  #Parte TL\n","from torch.nn.functional import relu\n","\n","\n","from torch import nn\n","\n","from sklearn.svm import SVC\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import pennylane as qml\n","from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n","from pennylane.operation import Tensor\n","\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(42)"]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"rJEVv50qYvmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = './data'\n","if not os.path.exists(directory):\n","    os.mkdir(directory)\n","\n","# Descomprimir el zip con el dataset\n","with zipfile.ZipFile(\"./drive/MyDrive/Colab Notebooks/QuantumKernelsPlayDogsVSCats/datasetCatsVSDogs.zip\",\"r\") as z:\n","    z.extractall(\"./data\")\n","\n","data_dir = './data/datasetCatsVSDogs'\n","\n","print(os.listdir(data_dir))\n","classes = os.listdir(data_dir + \"/train\")\n","print(classes)"],"metadata":{"id":"YOq4PitsF_lp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Flatten, MaxPooling2D"],"metadata":{"id":"yCnA4M_sz0fN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = VGG16(weights='imagenet')\n","model = tf.keras.Model(inputs=base_model.input,      \n","outputs=base_model.get_layer('block5_pool').output)\n","#model.summary()\n","modelAux = Sequential()\n","modelAux.add(model)\n","modelAux.summary()"],"metadata":{"id":"PUBx_FjZjafZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#layer19 = model.layers[18]\n","\n","modelAux.add(Conv2D(64, (1,1), activation='relu'))\n","modelAux.add(Conv2D(32, (1,1), activation='relu'))\n","modelAux.add(MaxPooling2D(pool_size=(2, 2)))\n","modelAux.add(Conv2D(16, (1,1), activation='relu'))\n","modelAux.add(Conv2D(8, (1,1), activation='relu'))\n","modelAux.add(Conv2D(4, (1,1), activation='relu'))\n","modelAux.add(MaxPooling2D(pool_size=(2, 2)))\n","modelAux.add(Flatten())"],"metadata":{"id":"zy_KFcFu1ryL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelAux.summary()"],"metadata":{"id":"7CSzYTdE3Nq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL"],"metadata":{"id":"_yazvNuQ5VhV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = \"./data/datasetCatsVSDogs/train\"\n","\n","categorias = ['cats', 'dogs']\n","\n","dataset = []\n","\n","def get_features(img_path):\n","    img = load_img(img_path, target_size=(224, 224))\n","    #img = cv2.imread(imgpath,1) # el 0 indica que se cargue la imagen en escala de grises, un 1 indica en color\n","    #img = cv2.resize( img, (224,224))\n","    x = img_to_array(img)\n","    x = np.expand_dims(x, axis=0) #la dimension de x era 3 y pasa a ser 4\n","    x = preprocess_input(x)\n","    flatten = modelAux.predict(x) #la dimension de flatten es 2\n","    print(flatten[0])\n","    return list(flatten[0])\n","\n","features, labels = [], []\n","\n","for categoria in categorias:\n","  path = os.path.join(train_dir, categoria) #ruta de la carpeta cats o la carpeta dogs\n","  label = categorias.index(categoria)\n","  i=0\n","  for img in os.listdir(path):\n","    if i <100:\n","      imgpath = os.path.join(path, img) #ruta de la imagen\n","      try:\n","          img = PIL.Image.open(imgpath)\n","      except PIL.UnidentifiedImageError:\n","              print(imgpath) #imprime el nombre de la imagen si se produce fallo al cargar alguna\n","      if (imgpath != \"./data/datasetCatsVSDogs/train/cats/_DS_Store\") & (imgpath != \"./data/datasetCatsVSDogs/train/dogs/_DS_Store\"): #este archivo esta en la carpeta pero no es una de las imagenes\n","        features.append(get_features(imgpath))\n","        labels.append(label)\n","    i += 1"],"metadata":{"id":"y5PosKOGi1ho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(features))"],"metadata":{"id":"UuI9ekJA5onc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split( features, labels, test_size=0.15, shuffle= True)"],"metadata":{"id":"HgwUul9gGWOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#n_qubits = len(X_train[0])\n","#n_qubits = len(X_train[0])\n","n_qubits = 4\n","print(n_qubits)"],"metadata":{"id":"S4LVfOtVGZ1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","projector = np.zeros((2**n_qubits, 2**n_qubits))\n","projector[0, 0] = 1\n","\n","@qml.qnode(dev_kernel)\n","def kernel(x1, x2):\n","    \"\"\"The quantum kernel.\"\"\"\n","    AngleEmbedding(x1, wires=range(n_qubits))\n","    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits))\n","    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))"],"metadata":{"id":"cFCMhOzJHeZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kernel(X_train[0], X_train[0])"],"metadata":{"id":"offeUs-D-NR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def kernel_matrix(A, B):\n","    \"\"\"Compute the matrix whose entries are the kernel\n","       evaluated on pairwise data from sets A and B.\"\"\"\n","    return np.array([[kernel(a, b) for b in B] for a in A])"],"metadata":{"id":"jaIs9bpd-SOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelQuantumKernel = SVC(kernel=kernel_matrix, probability = True).fit(X_train, y_train)"],"metadata":{"id":"7s1tJS24-V_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = modelQuantumKernel.predict(X_test) #predice sobre el test set"],"metadata":{"id":"in-og6MC-bWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(accuracy_score(predictions, y_test)) #calcula la precision"],"metadata":{"id":"XaYZZFPw-cBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install dill"],"metadata":{"id":"wuc5MaI7Ka88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import dill"],"metadata":{"id":"QuInjvykKeHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(modelQuantumKernel, 'VGG16_QSVM_definitivo.pth', pickle_module=dill) #necesario dill para poder cargarlo en vs code"],"metadata":{"id":"-ZKGjafWZyhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model = SVC(kernel=kernel_matrix, probability = True)\n","loaded_model = torch.load('VGG16_QSVM_definitivo.pth',map_location=device, pickle_module=dill)"],"metadata":{"id":"aA2-hQjJ8uSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagePath = './data/datasetCatsVSDogs/test/cats/cat.4001.jpg'\n","\n","imagenToPredict=[]\n","\n","imagenToPredict.append(get_features(imagePath)) #le debo aplicar a la imagen el mismo preprocesado que a las que se usaron para entrenar"],"metadata":{"id":"BQT9rhn4Yu7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediccion = loaded_model.predict_proba(imagenToPredict)\n","\n","#print('La predicción es:', predictedClass[0], ', ', categorias[predictedClass[0]])"],"metadata":{"id":"W9OgdIe6ZM4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prediccion)"],"metadata":{"id":"RwXlT3RYn3zc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","for i in prediccion[0]:\n","  if count == 0:\n","    catProbability = i\n","  else:\n","    dogProbability = i\n","  count += 1\n","\n","\n","if catProbability > dogProbability:\n","  classPredicted = \"Cat\"\n","else:\n","  classPredicted = \"Dog\"\n","  \n","print('La predicción es:', classPredicted)\n","\n"],"metadata":{"id":"Kqhr49I2oFIU"},"execution_count":null,"outputs":[]}]}