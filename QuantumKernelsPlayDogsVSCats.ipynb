{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMsid/5Jq9iYUkBK2A0ELsO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **IMPORTS AND CHECKING OF THE GPU**"],"metadata":{"id":"8cce_9K3y1H9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"d03vlNLWzxEA"},"outputs":[],"source":["#import PyTorch libraries\n","import os\n","%pylab inline\n","import torch\n","import torchvision\n","from torch import nn\n","import torch.optim as optim\n","import tarfile\n","from torchvision.datasets.utils import download_url\n","from torch.utils.data import random_split\n","import zipfile\n","from google.colab import drive\n","drive.mount('/content/drive') #lo concecto con mi drive\n","\n","#for TensorBoard\n","%load_ext tensorboard\n","from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter()\n","\n","#Import visualization library\n","import matplotlib.pyplot as plt\n","\n","#Verify PyTorch version\n","print(torch.__version__)"]},{"cell_type":"code","source":["#Check to see if we have a GPU to use for training\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('A {} device was detected.'.format(device))\n","\n","#Print the name of the cuda device, if detected\n","if device == 'cuda':\n","  print (torch.cuda.get_device_name(device=device))"],"metadata":{"id":"yKpWyYwNdq8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **LOADING THE DATA**"],"metadata":{"id":"pzg4vQhQDB-1"}},{"cell_type":"code","source":["directory = './data'\n","if not os.path.exists(directory):\n","    os.mkdir(directory)"],"metadata":{"id":"6nCtmjGK3XH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Descomprimir el zip con el dataset\n","with zipfile.ZipFile(\"./drive/MyDrive/Colab Notebooks/QuantumKernelsPlayDogsVSCats/datasetCatsVSDogs.zip\",\"r\") as z:\n","    z.extractall(\"./data\")"],"metadata":{"id":"SO-XdyhjtCYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = './data/datasetCatsVSDogs'\n","\n","print(os.listdir(data_dir))\n","classes = os.listdir(data_dir + \"/train\")\n","print(classes)"],"metadata":{"id":"CJdRj6n_15wc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","from torchvision.utils import save_image"],"metadata":{"id":"iROcXanm3c_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.Resize((32,32)),\n","     transforms.ToTensor()])\n","     #transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])  #transforma todas las imagenes en el mismo tamaño de 32x32 pixeles\n","\n","dataset = ImageFolder(data_dir+'/train', transform=transform)\n","type(dataset)"],"metadata":{"id":"CkKEZlZkLHLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.Resize((32,32)),\n","     transforms.ToTensor()])  #transforma todas las imagenes en el mismo tamaño de 32x32 pixeles\n","\n","dataset = ImageFolder(data_dir+'/train', transform=transform)\n","\n","\n","dataAugmentation_transform = transforms.Compose([\n","     #transforms.ToPILImage(),\n","     transforms.Resize((32,32)),\n","     #transforms.RandomCrop((30,30)),\n","     #transforms.ColorJitter(brightness=0.5),\n","     transforms.RandomRotation(degrees=45),\n","     transforms.RandomHorizontalFlip(p=0.5),\n","     transforms.RandomVerticalFlip(p=0.5),\n","     transforms.RandomGrayscale(p=0.2),\n","     transforms.ToTensor()\n","     ])\n","\n","datasetAugmented = ImageFolder(data_dir+'/train', transform= dataAugmentation_transform)\n","\n","#img_num = 0\n","#for img,label in datasetAugmented:\n","#  save_image(img, 'img'+str(img_num)+'.jpg')\n","#  img_num += 1\n","\n","\n","dataset1= torch.utils.data.ConcatDataset([dataset, datasetAugmented])"],"metadata":{"id":"TRDjZ-4O3eYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.imgs[-10:]"],"metadata":{"id":"x7DOkbo4hIV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, label = dataset[0]\n","print(len(dataset))\n","print(img.shape, label)\n","print(dataset.classes)\n","print(dataset)"],"metadata":{"id":"7NaTz6PR5N3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Para imprimir un par de imagenes del dataset\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n","\n","\n","def show_example(img, label):\n","    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n","    plt.imshow(img.permute(1, 2, 0))"],"metadata":{"id":"6KI1KNzUGgz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_example(*dataset[0])"],"metadata":{"id":"JkxefbiBGnwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_example(*dataset[8000])"],"metadata":{"id":"I1QaMzX7Gxee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **TRAINING AND VALIDATION DATASETS**"],"metadata":{"id":"oLmp_EHdOXFa"}},{"cell_type":"markdown","source":["A partir del dataset formado por todas las imagenes de train, se separa en el dataset de train (train_ds) y el dataset para validation (val_ds)"],"metadata":{"id":"7JWT7eMZz0BV"}},{"cell_type":"code","source":["#Creación del validation set\n","random_seed = 42\n","torch.manual_seed(random_seed);"],"metadata":{"id":"-Pz_tcl4Q1GS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_size = 500 #aquí se ajusta el tamaño del validation set\n","train_size = len(dataset) - val_size\n","\n","train_ds, val_ds = random_split(dataset, [train_size, val_size])\n","len(train_ds), len(val_ds)"],"metadata":{"id":"ScFJztG8OfP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Luego el train_ds y el val_ds se separan cada uno de ellos en batches de imagenes"],"metadata":{"id":"lzM9h9Jj0CnT"}},{"cell_type":"code","source":["from torch.utils.data.dataloader import DataLoader\n","\n","batch_size=32 #aquí se ajusta el tamaño de los batch, se suele ir doblando 64, 128, 256..."],"metadata":{"id":"0S3Lp50qWYS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creacion del train dataloader y validation dataloader que crean los batches\n","train_dl = DataLoader(train_ds, \n","                      batch_size, \n","                      shuffle=True, \n","                      num_workers=2, \n","                      pin_memory=True)\n","val_dl = DataLoader(val_ds, \n","                    batch_size*2, \n","                    num_workers=2, \n","                    pin_memory=True) #duplicamos el batch_size para el validation dataloader porque no vamos usar gradiente para la validation por lo que solo necesitaremos la mitad de la memoria"],"metadata":{"id":"v3tfDO8TWYeh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#funcion para mostrar uno de los batches\n","from torchvision.utils import make_grid\n","\n","def show_batch(dl):\n","    for images, labels in dl:\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","        ax.set_xticks([]); ax.set_yticks([])\n","        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n","        break\n","\n","#mostramos uno de los batches del train_dl\n","show_batch(train_dl)"],"metadata":{"id":"G1gmzRgOYhIc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **DEFINING DE MODEL (CNN)**"],"metadata":{"id":"ot0BG_9qjYjZ"}},{"cell_type":"code","source":["#función que realiza la operación de convolution\n","def apply_kernel(image, kernel):\n","    ri, ci = image.shape       # image dimensions\n","    rk, ck = kernel.shape      # kernel dimensions\n","    ro, co = ri-rk+1, ci-ck+1  # output dimensions\n","    output = torch.zeros([ro, co])\n","    for i in range(ro): \n","        for j in range(co):\n","            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)\n","    return output"],"metadata":{"id":"3PpKyem3jKBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MODELO DE PRUEBA CON UNA SOLA CONVOLUTIONAL LAYER\n","simple_model = nn.Sequential(\n","    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1), #3 canales de entrada (,G,B), 8 canales de salida, kernel de 3x3, stride de 1 y padding de 1\n","    nn.MaxPool2d(2, 2) # reduce a la mitad el alto y ancho de las imagenes\n",")"],"metadata":{"id":"HNxasTRpOVDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for images, labels in train_dl:\n","    print('images.shape:', images.shape)\n","    out = simple_model(images)\n","    print('out.shape:', out.shape)\n","    break\n","#toma un batch de 128 imagenes, 3 canales (R,G,B) e imagenes de 128x128 pixeles y devuelve --> un batch de 128 imagenes, 8 canales e imagenes de 64x64 pixeles"],"metadata":{"id":"vHlURfeaPPot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Primero definimos un modelo base llamado ImageClassificationBase que contiene métodos (funciones) de ayuda para el training y validation, y que son comunmente usadas."],"metadata":{"id":"QVLDZrv8Q9ZX"}},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"5rxAzBpzFEqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch): #self representa el objeto que se va a ir creando eventualmente (sería como el propio modelo)\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions, se pasa el batch de images al modelo(self)\n","        loss = F.cross_entropy(out, labels) # Calculate loss       \n","        #acc = accuracy(out, labels)           # Calculate accuracy\n","        return loss\n","        #return {'train_loss': loss.detach(), 'train_acc': acc}\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions, se pasa el batch de images al modelo(self)\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc} #devuelve la perdida de validation y la precisión de validation             #COMENTADO PARA IMPRIMIR TRAIN_ACC EN TB\n","        \n","    def validation_epoch_end(self, outputs): #toma las perdidas y precisiones de todos los diferentes batches del validation data y los combina calculando su media y devuelve una unica perdida y precisión para todo el validation set\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}                                                            #COMENTADO PARA IMPRIMIR TRAIN_ACC EN TB\n","    \n","    def epoch_end(self, epoch, result): #toma los resultados del epoch y los muestra\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","        \n","def accuracy(outputs, labels): #esta funcion calcula la precision de la prediccion\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds)) #devuelve la etiqueta(label) que más aparece y la compara con las verdaderas etiquetas"],"metadata":{"id":"_N2NwkWIRG7N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora creamos nuestro propio modelo que extiende el ImageClassificationBase"],"metadata":{"id":"sHS8LdpWTHYQ"}},{"cell_type":"code","source":["class CatsVSDogsCnnModel(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","        self.network = nn.Sequential( #self.network va pasando la salida de una capa a la entrada de la siguiente\n","            #input: 3 x 32 x 32\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1), #3 canales de entrada y 32 canales de salida, es decir 32 kernels\n","            #output: 32 x 32 x 32\n","            nn.ReLU(), #aplica la funcion de activacion, los valores negativos los convierte en 0 y los positivos los mantiene\n","            #output: 32 x 32 x 32\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), #hay 64 kernels\n","            #output: 64 x 32 x 32\n","            nn.ReLU(),\n","            #output: 64 x 32 x 32\n","            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), #en esta capa no se incrementa el numero de canales, pero aun así al incluir estas capas se hace que haya mas valores que puedan ser entrenados en el modelo\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n","\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n","            #se podrían seguir añadiendo capas convolucionales y mas Poolings, hasta aquí tenemos 6 convolutional layers\n","\n","            nn.Flatten(), #aplanamos el output final, es decir, lo convertimos a vector\n","            nn.Linear(256*4*4, 1024), #le pasamos como input el vector a una capa linear\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 2))\n","        \n","    def forward(self, xb):\n","        return self.network(xb)"],"metadata":{"id":"tkP-4IjgTOom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = CatsVSDogsCnnModel()\n","model"],"metadata":{"id":"UQTohZ9jo-C9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Probar el modelo con un batch de imagenes del train_dl para ver que funciona correctamente"],"metadata":{"id":"Rv7GN50-pg11"}},{"cell_type":"code","source":["for images, labels in train_dl:\n","    print('images.shape:', images.shape)\n","    out = model(images)\n","    print('out.shape:', out.shape)\n","    print('out[0]:', out[0])\n","    break\n","#devuelve esto:\n","  #images.shape: torch.Size([128, 3, 32, 32])  --> Toma como entrada un batch de 128 imagenes, de 3 canales y 32x32 pixeles\n","  #out.shape: torch.Size([128, 2]) --> la salida es un batch de 128 vectores con 2 valores cada vector\n","  #out[0]: tensor([-0.0225, -0.0190], grad_fn=<SelectBackward0>)  --> el vector 0 tiene esos valores siendo el primero la probabilidad de ser un gato y la segunda la de ser un perro"],"metadata":{"id":"0Cjb5wJcpo89"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Funciones alternativas para elegir GPU o CPU, mover los datos a la gpu..."],"metadata":{"id":"QVWO8nu7xeJt"}},{"cell_type":"code","source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"],"metadata":{"id":"M4hJ7ON8rnu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = get_default_device()\n","device\n","#vemos que hay GPU disponible (\"cuda\")"],"metadata":{"id":"GmpzIQu7x1hU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora pasamos los training y validation data loaders a la gpu para pasar automaticamente los batches de datos a la gpu, y con to_device se pasa el modelo a la gpu."],"metadata":{"id":"0x-KRqhFyJWM"}},{"cell_type":"code","source":["train_dl = DeviceDataLoader(train_dl, device)\n","val_dl = DeviceDataLoader(val_dl, device)\n","to_device(model, device);"],"metadata":{"id":"yFDT8Q2VyWSr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **TRAINING THE MODEL**"],"metadata":{"id":"42iv4kQkykOG"}},{"cell_type":"markdown","source":["Vamos a definir 2 funciones: `fit` y `evaluate` para entrenar el modelo usando descenso de gradiente y evaluar su actuación en el validation set."],"metadata":{"id":"OjuMZ4K8zBkN"}},{"cell_type":"code","source":["@torch.no_grad() #indica que mientras se ejecute la funcion evaluate no se compute ningún gradiente\n","def evaluate(model, val_loader):\n","    model.eval() #informa a pytorch de que estamos evaluando el modelo por lo que no habrá randomize\n","    outputs = [model.validation_step(batch) for batch in val_loader] #obtiene batches de imagenes del val_dl y los pasa a la validation_step function que devolvera la loss de la validation\n","    return model.validation_epoch_end(outputs) #calcula la media de las loss y devuelve un unico output\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD): #se le pasa el numero de epochs y el optimizador que usaremos SGD (stocastic gradient descend).\n","    history = []\n","    optimizer = opt_func(model.parameters(), lr) #el optimizador toma los model.parameters que son los weights y biases de todas las capas y los va actualizando\n","    for epoch in range(epochs): #para cada epoch va a ver una fase de training y otra de validation\n","        # Training Phase \n","        model.train() #informa a pytorch de que estamos entrenando el modelo\n","        train_losses = [] #se mantiene un seguimiento de las perdidas(losses)\n","        for batch in train_loader: #cogemos batches de imagenes del train_dl\n","            loss = model.training_step(batch) #esta funcion esta definida en ImageClassificationBase class y devuelve la perdida(loss) para el batch que se le pasa como input\n","            train_losses.append(loss) #para obtener al final la loss total del epoch\n","            loss.backward() #calcula los gradientes\n","            optimizer.step() #se aplica el decenso de gradiente con un optimizador\n","            optimizer.zero_grad() #pone a 0 los gradientes calculados en loss.backwards\n","        # Validation phase\n","        result = evaluate(model, val_loader) #llama a la funcion evaluate definida más arriba en este bloque y devuelve el validation loss y validation accuracy\n","        result['train_loss'] = torch.stack(train_losses).mean().item() #calcula la media del train_losses para el epoch entero\n","        model.epoch_end(epoch, result) #imprime el numero de epoch, el training loss, validation loss y validation accuracy\n","        history.append(result) #el resultado se añade al registro de resultados anteriores\n","    return history"],"metadata":{"id":"xwhaCE0Gynx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = to_device(CatsVSDogsCnnModel(), device) #actualizamos el modelo con el que se ha pasado a la GPU"],"metadata":{"id":"odNBIkdf2-UP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(model, val_dl)"],"metadata":{"id":"LjG2FXQ62-cc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 20 #vamos a entrenar con 10 epochs\n","opt_func = torch.optim.Adam #usamos la función de optimizacion Adam\n","lr = 0.0001 #learning rate general"],"metadata":{"id":"YzcY2WpZ2-rl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entrenamos el modelo:"],"metadata":{"id":"83eNB7Sx66yF"}},{"cell_type":"code","source":["history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func) #coge batches de imagenes del dataset y las pasa por el modelo, coge la salida, calcula gradientes, aplica SGD, cambiar los  weights y biases ligeramente para reducir la loss y repetir eso para todos los batches de cada epoch\n","#se puede ver que la máxima val_acc (accuracy) la alcanza con 9 epochs"],"metadata":{"id":"5BhMMdNb60GM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for n_iter in range(num_epochs):\n","    writer.add_scalar('Loss/test', history[n_iter]['val_loss'], n_iter)\n","    writer.add_scalar('Accuracy/test', history[n_iter]['val_acc'], n_iter)\n","    writer.add_scalar('Loss/train', history[n_iter]['train_loss'], n_iter)"],"metadata":{"id":"EbjeTRPfKMlr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graficar las validation set accuracies para ver como el modelo mejora con los distintos epochs:"],"metadata":{"id":"eaJ5hERb9LFL"}},{"cell_type":"code","source":["def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');"],"metadata":{"id":"VzUTuug39SE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_accuracies(history) \n","#se puede aumentar la accuracy aumentando el numero de concolutional layers o el numero de canales en cada concolutional layer."],"metadata":{"id":"-p82_Rjt9WLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graficar las training losses y las validation losses para ver como el modelo mejora con los distintos epochs:"],"metadata":{"id":"aEvKMBF5_jlX"}},{"cell_type":"code","source":["def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');"],"metadata":{"id":"Cl2kWZZT_7c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_losses(history)\n","#a partir del epoch nº 9 el training_loss sigue disminuyendo pero el validation_loss vuelve a aumentar, se produce overfitting"],"metadata":{"id":"I3mDZuCF_-CV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **TESTING WITH INDIVIDUAL IMAGES**"],"metadata":{"id":"gW_TyW8kB8e1"}},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.Resize((32,32)),\n","     transforms.ToTensor()])  #transforma todas las imagenes en el mismo tamaño de 128x128 pixeles\n","\n","test_dataset = ImageFolder(data_dir+'/test', transform=transform)#creamos un dataset con la clase ImageFolder"],"metadata":{"id":"3o2XVArzCCsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Función auxiliar para hacer la predicción de una imagen:"],"metadata":{"id":"I-8mw945Cit7"}},{"cell_type":"code","source":["def predict_image(img, model):\n","    # Convert to a batch of 1\n","    xb = to_device(img.unsqueeze(0), device)\n","    # Get predictions from model\n","    yb = model(xb)\n","    # Pick index with highest probability\n","    _, preds  = torch.max(yb, dim=1)\n","    # Retrieve the class label\n","    return dataset.classes[preds[0].item()]"],"metadata":{"id":"d_bSMa7uCnvT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pruebas con algunas imágenes:"],"metadata":{"id":"oHq7DsMeCwoU"}},{"cell_type":"code","source":["img, label = test_dataset[0]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"],"metadata":{"id":"F6tBdXJpCypm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, label = test_dataset[2000]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"],"metadata":{"id":"pyNWzJBHDFp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Por ultimo, miramos la loss y accuracy generales del modelo sobre el test set. Estos valores deberían ser similares a los del validation set, si no, necesitaremos un mejor validation set que sea mas similar al test set"],"metadata":{"id":"ue8Wa0WfEQ0c"}},{"cell_type":"code","source":["test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n","result = evaluate(model, test_loader)\n","result"],"metadata":{"id":"iXyHwKKAEhac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **SAVING AND LOADING THE MODEL**"],"metadata":{"id":"aiDdki-tFDP-"}},{"cell_type":"code","source":["torch.save(model.state_dict(), 'catsVSdogs-cnn.pth') #guarda el modelo en ese archivo"],"metadata":{"id":"vKPZcxyEFGmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = to_device(CatsVSDogsCnnModel(), device) #crea un nuevo modelo 2 "],"metadata":{"id":"McmjSPK2FJOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.load_state_dict(torch.load('catsVSdogs-cnn.pth')) #carga el modelo 2 con el modelo que habiamos guardado en el archivo"],"metadata":{"id":"5Q-W7NobFKwC","executionInfo":{"status":"ok","timestamp":1649417273346,"user_tz":-120,"elapsed":6,"user":{"displayName":"ALEJANDRO ARGÜELLO SUAREZ","userId":"11454197765598937155"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b50e63a7-5dac-4011-8cec-1dc8a5b0c827"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["evaluate(model2, test_loader) #comprobamos que el modelo cargado tiene la misma accuracy que anteriormente"],"metadata":{"id":"OA7kQae_FQXa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **TENSORBOARD**"],"metadata":{"id":"cE307akhkEns"}},{"cell_type":"code","source":["%tensorboard --logdir=runs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"u-RK9SyxkHW5","executionInfo":{"status":"ok","timestamp":1649417286471,"user_tz":-120,"elapsed":5691,"user":{"displayName":"ALEJANDRO ARGÜELLO SUAREZ","userId":"11454197765598937155"}},"outputId":"ad530ea4-fb39-4470-fd56-5adeb719bfc3"},"execution_count":null,"outputs":[]}]}